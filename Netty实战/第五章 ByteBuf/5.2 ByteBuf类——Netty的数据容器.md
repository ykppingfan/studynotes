&emsp;&emsp;因为所有的网络通信都设计字节序列的移动，所以高效易用的数据结构明显是必不可少的。Netty的ByteBuf实现满足并超越了这些需求。让我们首先来看看它是如何通过使用不同的索引来简化对它所包含的数据的访问的吧。

## 5.2.1 它是如何工作的

&emsp;&emsp;ByteBuf维护了两个不同的索引：一个用于读取，一个用于写入。当你从ByteBuf读取时，它的readerIndex将会被递增已经被读取的字节数。同样的，当你写入ByteBuf时，它的writeIndex也会被递增。图5-1展示了一个空ByteBuf的布局结构和状态。![image](http://img.blog.csdn.net/20140716154654843?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYWJjX2tleQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

&emsp;&emsp;要了解这些索引两两之间的关系，请考虑一下，如果打算读取字节直到readerIndex达到和writeIndex同样的值时会发生什么。在那时，你将会到达“可以读取的”数据的末尾。就如同试图读取超出数组末尾的数据一样，试图读取超出该点的数据将会触发一个IndexOutofBoundsException。

&emsp;&emsp;**名称以read或者write开头的ByteBuf方法，将会推进其对应的索引，而名称以set或者get开头的操作则不会**。后面的这些方法将在作为一个参数传入的一个相对索引上执行操作。

&emsp;&emsp;可以指定ByteBuf的最大容器。试图移动写索引（即writerIndex）超过这个值将会触发一个异常。（默认的限制是Integer.MAX_VALUE。）

## 5.2.2 ByteBuf的使用模式

&emsp;&emsp;在使用Netty时，你将遇到几种常见的围绕ByteBuf而构建的使用模式。在研究它们时，我们心里想着图5-1会有所裨益——一个由不同的索引分别控制读访问和写访问的字节数组。

1. 堆缓冲区

&emsp;&emsp;最常用的ByteBuf模式是将数据存储在JVM的堆空间中。这种模式被称为支撑数组（backing array），**它能在没有使用池化的情况下提供快速的分配和释放**。这种方式，如代码清单5-1所示，非常适合于有遗留的数据需要处理的情况。

&emsp;&emsp;代码清单5-1 支撑数组
```
Channel channel = ctx.channel();
ByteBuf heapBuf = Unpooled.buffer();
if (heapBuf.hasArray()) { //检查ByteBuf是否有一个支撑数组
    byte[] array = heapBuf.array();//如果有，则获取对该数组的引用
    int offset = heapBuf.arrayOffset() + heapBuf.readerIndex(); //计算第一个字节的偏移量
    int length = heapBuf.readableBytes(); //获得可读字节数
    handleArray(array, offset, length); //使用数组，偏移量和长度作为参数调用你的方法
}
```
&emsp;&emsp;注意 当hasArray()方法返回FALSE时，尝试访问支撑数组将触发一个UnsupportedOperationException。这个模式类似于JDK的ByteBuffer的用法。

2. 直接缓冲区

&emsp;&emsp;直接缓冲区是另外一种ByteBuf模式。我们期望用于对象创建的内存分配永远都来自于堆中，但这并不是必须的——NIO在JDK1.4中引入的ByteBuffer类允许JVM实现通过本地调用来分配内存。这主要是为了避免在每次调用本地I/O操作之前（或者之后）将缓冲区的内容赋值到一个中间缓冲区（或者从中间缓冲区把内容复制到缓冲区）。

&emsp;&emsp;ByteBuffer的Javadoc明确指出：“**直接缓冲区的内容将驻留在常规的会被垃圾回收的堆之外**。”这也就解释了为何直接缓冲区对于网络数据传输是理想的选择。**如果你的数据包含在一个在堆上分配的缓冲区中，那么事实上，在通过套接字发送它之前，JVM将会在内部把你的缓冲区复制到一个直接缓冲区中**。

&emsp;&emsp;直接缓冲区的主要缺点是，相对于基于堆的缓冲区，它们的分配和释放都较为昂贵。如果你正在处理遗留代码，你也可能会遇到另外一个缺点：因为数据不是在堆上，所以你不得不进行一次复制（此次复制的原因是因为Java对象只能处理JVM内存中的对象，所以必须将直接内存的对象复制到堆），如代码清单5-2所示。

&emsp;&emsp;显然，与使用支撑数组相比，这设计的工作更多。因此，**如果事先知道容器中的数据将会被作为数组来访问，你可能更愿意使用堆内存**。

3. 符合缓冲区

&emsp;&emsp;第三种也是最后一种模式使用的是复合缓冲区，它为多个ByteBuf提供一个聚合视图。在这里你可以根据需要添加或者删除ByteBuf实例，这是一个JDK的ByteBuffer实现完全缺失的特性。

&emsp;&emsp;Netty通过一个ByteBuf子类——CompositeByteBuf——实现了这个模式，它提供了一个将多个缓冲区表示为单个合并缓冲区的虚拟表示。

&emsp;&emsp;**警告** CompositeByteBuf中的ByteBuf实例可能同时包含直接内存分配和非直接内存分配。如果其中只有一个实例，那么对CompositeByteBuf上的hasArray()方法的调用将返回改组件上的hasArray()方法的值；否则它将返回FALSE。

&emsp;&emsp;为了举例说明，让我们考虑一下一个由两部分——头部和主体——组成的将通过HTTP协议传输的消息。这两部分由应用程序的不同模块产生，将会在消息被发送的时候组装。该应用程序可以选择为多个消息重用相同的消息主体。当这种情况发生时，对于每个消息都会创建一个新的头部。

&emsp;&emsp;因为我们不想为每个消息都重新分配这两个缓冲区，所以使用CompositeByteBuf是一个完美的选择。它在消除了没必要的复制的同时，暴露了通用的ByteBuf API。图5-2展示了生成的消息布局![image](http://img.blog.csdn.net/20140716165005489?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvYWJjX2tleQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

&emsp;&emsp;代码清单5-3展示了如何通过使用JDK的ByteBuffer来实现这一需求。创建了一个包含两个ByteBuffer的数组用来保存这些消息组件，同时创建了第三个ByteBuffer用来保存所有这些数据的副本。代码略

&emsp;&emsp;代码清单5-4 使用CompositeByteBuf的复合缓冲区模式
```
CompositeByteBuf messageBuf = Unpooled.compositeBuffer();
ByteBuf headerBuf = ...;
ByteBuf bodyBuf = ...;
messageBuf.addComponents(headerBuf, bodyBuf); //将ByteBuf实例追加到CompositeByteBuf

messageBuf.removeComponent(0); //删除位于索引位置为0的ByteBuf
for (ByteBuf buf : messageBuf) { //遍历所有的ByteBuf实例
    System.out.println(buf.toString());
}
```
&emsp;&emsp;CompositeByteBuf可能不支持访问其支撑数组，因此访问CompositeByteBuf中的数据类似于直接缓冲区的模式。

&emsp;&emsp;需要注意的是，Netty使用了CompositeByteBuf来优化套接字的I/O操作，尽可能地消除了由JDK的缓冲区实现所导致的性能以及内存使用率的惩罚。这种优化发生在Netty的核心代码中，因此不会被暴露出来，但是你应该知道它所带来的影响。