&emsp;&emsp;BlockingQueue用于实现生产者和消费者一个不错的选择。它可以很自然的实现作为生产者和消费者的内存缓冲区。但是BlockingQueue并不是一个高性能的实现，它完全使用锁和阻塞等待来实现线程间的同步。在高并发场合，它的性能并不是特别的优越。就像之前我已经提过的：ConcurrentLinkedQueue是一个高性能队列，但是BlockingQueue只是为了方便数据共享。

&emsp;&emsp;而ConcurrentLinkedQueue的秘诀就在于大量使用了无锁的CAS操作。同理，如果我们使用CAS来实现生产者-消费者模式，也同样可以获得客官的性能提升。不过正如大家所见，使用CAS进行变成是非常困难的，但是有一个好消息是，目前一个现成的Disruptor框架，它已经帮助我们实现了这一个功能。

## 5.4.1 无锁的缓存框架：Disruptor

&emsp;&emsp;Disruptor框架是由LMAX公司开发的一款高效的无锁内存队列。它使用了无锁的方式实现了一个环形队列，非常适合于实现生产者和消费者模式，比如时间和消息的发布。在Disruptor中，别出心裁的使用了环形队列（RingBuffer）来代替普通的线性队列，这个环形队列内部实现为一个普通的数组。对于一般的队列，势必要提供队列同步head和尾部tail两个指针，用于出队和入队，这样无疑就增加了线程协作的复杂度。但如果队列是环形的，则只需要对外提供一个当前位置cursor，利用这个指针既可以进行入队也可以进行出队操作。由于环形队列的缘故，队列的总大小必须事先指定，不能动态扩展。**为了能够快速从一个序列（sequence）对应到数组的实际位置（每次有元素入队，序列就加1），Disruptor要求我们必须将数组的大小设置为2的整数次方。这样通过sequence&（queueSize-1）就能立即定位到实际的元素位置index。这个要比取余（%）操作快得多**。

&emsp;&emsp;如果大家不理解上面的sequence&（queueSize-1），我在这里再简单说明一下。如果queueSize是2的整数次幂，则这个数字的二进制表示必然是10/100/1000/10000等形式。因此，queueSize-1的二进制则是一个全1的数字。因此它可以将sequence限定在queueSize-1范围内，并且不会有任何以为是浪费的。

&emsp;&emsp;如图5.3所示，显示了RingBuffer的结构。生产者向缓冲区中写入数据，而消费者从从中读取数据。生产者写入数据时，使用CAS操作，消费者读取数据时，为了防止多个消费者处理同一个数据，也使用CAS操作进行数据保护。

&emsp;&emsp;这种固定大小的环形队列的另一个好处就是可以做到完全的内存复用。在系统的运行过程中，不会有新的空间需要分配或者老的空间需要回收。因此，大大减少系统分配空间以及回收空间的额外开销。![image](http://s7.51cto.com/wyfs01/M01/0F/5D/wKioOVHBJveTGuVqAABaHrPAN9A562.jpg)

## 5.4.2 用Disruptor实现生产者-消费者案例

&emsp;&emsp;现在我们已经基本了解了Disruptor的基本实现。在本节，我们将展示一下Disruptor的基本使用和API，这里，我们使用的半包是Disruptor-3.3.2，不同版本的Disruptor可能会有细微的差别，也请大家留意。

&emsp;&emsp;这里，我们的生产者不断产生整数，消费者读取生产者的数据，并计算其平方。

&emsp;&emsp;首先，我们还是需要一个代表数据的PCData：
```
public class PCData {
    private long value;
    public long getValue() {
        return value;
    }
    public void setValue(long value) {
        this.value = value;
    }
}
```
&emsp;&emsp;消费者实现为WorkHandler接口，它来自Disruptor框架：
```
public class Consumer implements WorkHandler<PCData> {
    @Override
    public void onEvent(PCData event) throws Exception {
        System.out.println(Thread.currentThread().getId() + ":Event: --"
        + event.getValue() * event.getValue() + "--");
    }
}
```
&emsp;&emsp;消费者的作用是读取数据进行处理。这里，数据的读取已经由Disruptor进行封装，onEvent()方法为框架的回调方法。因此，这里只需要简单的进行数据处理即可。

&emsp;&emsp;还需要一个产生PCData的工厂类。它会在Disruptor系统初始化时，构造所有的缓冲区中的对象实例（之前说过Disruptor会预先分配空间）：
```
public class PCDataFactory implements EventFactory<PCData>{
    public PCData newInstance() {
        return new PCData();
    }
}
```
&emsp;&emsp;接着，让我们来看一下生产者，它比前面及各类稍微复杂一点：
```
public final class Producer 
{
    private final RingBuffer<PCData> ringBuffer;

    public Producer(RingBuffer<PCData> ringBuffer) 
    {
        this.ringBuffer = ringBuffer;
    }

    public void pushData(ByteBuffer bb) 
    {
        long sequence = ringBuffer.next(); //Grab the next swquence
        try {
            PCData event = ringBuffer.get(sequence); // Get the entry in the Disruptor 
                                                    // for the sequence

            event.setValue(bb.getLong(0));//Fill with data
        } 
        finally 
        {
            ringBuffer.publish(sequence);
        }
    }
}
```
&emsp;&emsp;生产者需要一个RingBuffer的引用，也就是环形缓冲区。它有一个重要的方法pushData()将产生的数据推入缓冲区。方法pushData()接收一个ByteBuffer对象。在ByteBuffer中可以用来包装任何数据类型。这里用来存储long整数，pushData()的功能就是将传入的ByteBuffer中的数据提取出来，并装载到环形缓冲区。

&emsp;&emsp;上述第12行代码，通过next()方法得到下一个可用的序列号。通过序列号，取得下一个空闲可用的PCData。并且将PCData的数据设为期望值，这个值最终会传递给消费者。最后，在第21行，进行数据发布。**只有发布后的数据才会真正被消费者看见**。

&emsp;&emsp;至此，我们的生产者、消费者和数据都已经准备就绪。只差一个统筹规划的主函数将所有的内容整合起来：
```
public static void main(String[] args) throws Exception
{
    Executor executor = Executors.newCachedThreadPool(); //建立线程池
    PCDataFactory factory = new PCDataFactory();
    //Specify the size of the ring buffer, must be power of 2.
    int bufferSize = 1024;
    Disruptor<PCData> disruptor = new Disruptor<PCData>(factory,
            bufferSize,
            executor,
            ProducerType.MULTI,
            new BlockingWaitStrategy()
    );
    disruptor.handleEventsWithWorkerPool(
            new Consumer(),
            new Consumer(),
            new Consumer(),
            new Consumer());
    disruptor.start();

    RingBuffer<PCData> ringBuffer = disruptor.getRingBuffer();
    Producer producer = new Producer(ringBuffer);
    ByteBuffer bb = ByteBuffer.allocate(8);
    for (long l = 0; true; l++)
    {
        bb.putLong(0, l);
        producer.pushData(bb);
        Thread.sleep(100);
        System.out.println("add data " + 1);
    }
}
```
&emsp;&emsp;上述代码第6行，设置缓冲区大小为1024.显然是2的整数次幂--一个合理的大小。第7~12创建了Disruptor对象。它封装了整个Disruptor库的使用，提供了一些便捷的API。第13~17行，设置了用于处理数据的消费者。这里设置了4个消费者实例，系统会将每一个消费者实例映射到一个线程中，也就是这里提供了4个消费者线程。第18行，启动并初始化Disruptor系统。在第23~29行中，由一个生产者不断的想缓冲区中存入数据。

&emsp;&emsp;系统执行后，你就可以得到类似Ixia的输出：
```
12:Event: --0--
add data 0
15:Event: --1--
add data 1
14:Event: --4--
add data 2
13:Event: --9--
add data 3
```
&emsp;&emsp;生产者和消费者正常工作。根据Disruptor的官方报告，Disruptor的性能要比BlockingQueue至少高一个数量级以上。如此诱人的性能，当然值得我们去尝试！

## 5.4.3 提高消费者的响应时间：选择合适的策略

&emsp;&emsp;当有新数据在Disruptor的唤醒缓冲区中产生时，消费者如何知道这些新产生的数据呢？或者说，消费者如何监控缓冲区中的信息呢？为此，Disruptor提供了几种策略，这些策略由WaitStrategy接口进行封装，主要有以下几种实现。

- BlockingWaitStrategy：这是默认的策略。使用BlockingWaitStrategy和使用BlockingQueue是非常类似的，它们都使用锁和条件（Condition）进行数据的监控和线程的唤醒。因为设计到线程的切换，BlockingWaitStrategy策略是最节省CPU，但是在高并发下性能表现最糟糕的一种等待策略。
- SleepingWaitStrategy：这个策略也是对CPU使用率非常保守的。它会在循环中不断等待数据。它会先进性自旋等待，如果不成功，则使用Thread.yield()让出CPU，并最终使用LockSupport.parkNanos(1)进行线程休眠，以确保不占用太多的CPU数据。因此，这个策略对于数据处理可能产生比较高的平均延时。它比较适合于对延时要求不是特别高的场合，好处是它对生产者线程的影响最小。典型的应用场景是异步日志。
- YieldingWaitStrategy：这个策略用于低延时的场合。消费者线程会不断循环监控缓冲区变化，在循环内部，它会使用Thread.yield()让出CPU给别的线程执行时间。如果你需要一个高性能的系统，并且对延时有较为严格的要求，则可以考虑这种策略。使用这种策略时，相当于你的消费者线程变身成为了一个内部执行了Thread.yield()的死循环。因此，你最好有多于消费真线程数量的逻辑CPU数量（这里的逻辑CPU，我指的是“双核四线程”中的哪个四线程），否则，整个应用恐怕都会受到影。
- BusySpinWaitStrategy：这个是最疯狂的等待策略了。它就是一个死循环！消费者线程会尽最大努力风控监控缓冲区的变化。因此，它会吃掉所有的CPU资源。你只有在对延迟非常苛刻的场合可以考虑使用它（或者说，你的系统真的非常繁忙）。因为在这里你等同开启了一个死循环监控，所以，你的物理CPU数量必须要大于消费者线程数。注意，我这里说的是物理CPU，如果你在一个物理核上使用超线程技术模拟两个逻辑和，另外一个逻辑核显然会受到这种超密集计算的影响而不能正常工作。

&emsp;&emsp;在上面的例子中，使用的是BlockingWaitStrategy（第11行）。读者可以替换这个实现，体验一下不同等待策略的效果。

## 5.4.4 CPU Cache的优化：解决伪共享问题

&emsp;&emsp;除了使用CAS和提供了各种不同的等待策略来提高系统的吞吐量外。Disruptor大有将优化进行到底的气势，它甚至尝试解决CPU缓存的伪共享问题。

&emsp;&emsp;什么是伪共享问题呢？我们知道，为了提高CPU的速度，CPU有一个高速缓存Cache。在高速缓存中，读写数据的最小单位为缓存行（Cache Line），它是从主存（memory）赋值到缓存（Cache）的最小单位，一般为32字节到128字节。

&emsp;&emsp;如果两个变量存放在一个缓存行中，在多线程访问中，可能会相互影响彼此的性能。如图5.4所示，假设X和Y在同一个缓存行。运行在CPU1上的线程更新了X，那么CPU2上的缓存行就会失效，同一行的Y即使没有修改也会变成无效，导致Cache无法命中。接着，如果在CPU2上的线程更新了Y，则导致CPU1上的缓存行又失效（此时，同一行的X又变得无法访问）。这种情况反反复复发生，五一是一个潜在的性能杀手。如果CPU经常不能命中缓存，那么系统的吞吐量就会急剧下降。![image](http://ifeve.com/wp-content/uploads/2013/01/cache-line.png)

&emsp;&emsp;为了使这种情况不发生，一种可行的做法就是在X变量的前后空间都先占据一定的位置（把它叫做padding吧，用来填充用的）。这样，当内存被读入缓存中时，这个缓存行中，只有X一个变量实际是有效地，因此就不会发生多个线程同时修改缓存行中不同变量而导致变量全体失效的情况，如图5.5所示。图略

&emsp;&emsp;为了实现这个目的，我们可以这么做：
```
public class FalseSharing implements Runnable {
    public final static int NUM_THREADS =2; //change
    public final static long ITERATIONS = 500L * 1000L * 1000L;
    private final int arrayIndex;

    private static VolatileLong[] longs = new VolatileLong[NUM_THREADS];
    static {
        for (int i=0; i< longs.length; i++) {
            longs[i] = new VolatileLong();
        }
    }

    public FalseSharing(final int arrayIndex) {
        this.arrayIndex = arrayIndex;
    }

    public static void main(String[] args) throws Exception {
        final long start = System.currentTimeMillis();
        runTest();
        System.out.println("duration = " + (System.currentTimeMillis() - start));
    }

    private static void runTest() throws InterruptedException {
        Thread[] threads = new Thread[NUM_THREADS];

        for (int i = 0; i < threads.length; i++) {
            threads[i] = new Thread(new FalseSharing(i));
        }

        for (Thread t : threads) {
            t.start();
        }

        for (Thread t : threads) {
            t.join();
        }
    }
    @Override
    public void run() {
        long i = ITERATIONS + 1;
        while (0 != --i) {
            longs[arrayIndex].value = i;
        }
    }
    
    public final static class VolatileLong {
        public volatile long value = 0L;
        public long p1,p2,p3,p4,p5,p6,p7; // comment out
    }
}
```
&emsp;&emsp;这里我们使用两个线程，因为我的计算机是双核的，大家可以根据自己的硬件配置修改参数NUM_THREADS（第2行）。我们准备一个数组longs（第6行），数组元素个数和线程数量一直。每个线程都会访问自己对应的longs中的元素（从第42行、第27行和第14行可以看到这一点）。

&emsp;&emsp;最后，最关键的一点就是VolatileLong。在第48行，准备了7个long型变量用来填充缓存。实际上，只有VolatileLong.value是会被使用的。而那些p1、p2等仅仅用于将数组中的第一个VolatileLong.value和第二个VolatileLong.value，防止他们进入同一个缓存行。

&emsp;&emsp;这里，我使用JDK8 64位的Java虚拟机，执行上述程序，输出如下：
```
duration = 3729
```
&emsp;&emsp;这说明系统花费了3秒多钟完成所有的操作。如果我注释掉第48行，也就是允许系统中两个VolatileLong.value放置在同一个缓存行中，程序输出如下：
```
duration = 21806
```
&emsp;&emsp;很明显，第48行的填充对系统的性能是非常有帮助的。

&emsp;&emsp;注意：由于各个JDK版本内部实现不一致，在某些JDK版本中（比如JDK8），会自动优化不使用的字段。浙江直接导致这种padding的伪共享解决方案失效。更多详细内容大家可以参考第6章中有关LongAddr的介绍。

&emsp;&emsp;Disruptor框架充分考虑了这个问题，它的核心组件Sequence会被非常频繁的访问（每次入队，它都会被加1），其基本结构如下：
```
class LhsPadding
{
    protected long p1,p2,p3,p4,p5,p6,p7;
}

class Value extends lhsPadding
{
    protected volatile long value;
}

class RhsPadding extends Value
{
    protected long p9, p10, p11, p12, p13, p14, p15;
}
public class Sequence extends RhsPadding {
    //省略具体实现
}
```
&emsp;&emsp;虽然在Sequence中，主要使用的只有value。但是，通过LhsPadding和RhsPadding，在这个value的前后安置了一些占位空间，是的value可以无冲突的存在于缓存中。

&emsp;&emsp;此外，对于Disruptor的环形缓存区RingBuffer，它内部的数组是通过以下语句构造的：
```
this.entries = new Object[sequence.getBufferSize() + 2*BUFFER_PAD]；
```
&emsp;&emsp;大家注意，实际产生的数组大小是缓冲区实际大小再加上两倍的BUFFER_PAD。这就相当于在这个数组的头部和尾部两段各增加了BUFFER_PAD个填充，使得整个数组被载入Cache时不会受到其他变量的影响而失效。